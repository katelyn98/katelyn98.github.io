<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Katelyn C. Morrison


  | publications

</title>
<meta name="description" content="Katelyn Morrison's personal website. Learn more about her latest research projects and more!
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<!-- <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" /> -->

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåå</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXXX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-XXXXXXXXX');
</script>




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>
    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://katelyn98.github.io//">
       Katelyn C. Morrison
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/travel/">
                travel
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2025</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="abrini2025proceeding" class="col-sm-8">
    
      <div class="title">Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Abrini, Mouad,
            
          
        
          
          
          
          
          
          

          

          
            
              Abend, Omri,
            
          
        
          
          
          
          
          
          

          

          
            
              Acklin, Dina,
            
          
        
          
          
          
          
          
          

          

          
            
              Admoni, Henny,
            
          
        
          
          
          
          
          
          

          

          
            
              Aichinger, Gregor,
            
          
        
          
          
          
          
          
          

          

          
            
              Alon, Nitay,
            
          
        
          
          
          
          
          
          

          

          
            
              Ashktorab, Zahra,
            
          
        
          
          
          
          
          
          

          

          
            
              Atreja, Ashish,
            
          
        
          
          
          
          
          
          

          

          
            
              Auron, Moises,
            
          
        
          
          
          
          
          
          

          

          
            
              Aufreiter, Alexander,
            
          
        
          
          
          
          
          
          

          

          
            
              and al.,
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2505.03770</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/abs/2505.03770" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This volume includes a selection of papers presented at the Workshop on Advancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in Philadelphia US on 3rd March 2025. The purpose of this volume is to provide an open access and curated anthology for the ToM and AI research community.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">abrini2025proceeding</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abrini, Mouad and Abend, Omri and Acklin, Dina and Admoni, Henny and Aichinger, Gregor and Alon, Nitay and Ashktorab, Zahra and Atreja, Ashish and Auron, Moises and Aufreiter, Alexander and et al.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2505.03770}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2505.03770, 2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2505.03770}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="sivaraman2025overrelyin" class="col-sm-8">
    
      <div class="title">Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Sivaraman, Venkatesh,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Epperson, Will,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>Workshop on Envisioning the Future of Interactive Health</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/pdf/2504.07423?" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>As AI-based clinical decision support (AI-CDS) is introduced in more and more aspects of healthcare services, HCI research plays an increasingly important role in designing for complementarity between AI and clinicians. However, current evaluations of AI-CDS often fail to capture when AI is and is not useful to clinicians. This position paper reflects on our work and influential AI-CDS literature to advocate for moving beyond evaluation metrics like Trust, Reliance, Acceptance, and Performance on the AI‚Äôs task (what we term the "trap" of human-AI collaboration). Although these metrics can be meaningful in some simple scenarios, we argue that optimizing for them ignores important ways that AI falls short of clinical benefit, as well as ways that clinicians successfully use AI. As the fields of HCI and AI in healthcare develop new ways to design and evaluate CDS tools, we call on the community to prioritize ecologically valid, domain-appropriate study setups that measure the emergent forms of value that AI can bring to healthcare professionals.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">sivaraman2025overrelyin</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Over-Relying on Reliance: Towards Realistic Evaluations of AI-Based Clinical Decision Support}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sivaraman, Venkatesh and Morrison, Katelyn and Epperson, Will and Perer, Adam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Workshop on Envisioning the Future of Interactive Health}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2504.07423?}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="bradshaw2025towardinte" class="col-sm-8">
    
      <div class="title">Toward Interpretable 3D Diffusion in Radiology: Token-Wise Attribution for Text-to-CT Synthesis</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Bradshaw, Aidan,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Mathur, Arpit,
            
          
        
          
          
          
          
          
          

          

          
            
              Dai, Weicheng,
            
          
        
          
          
          
          
          
          

          

          
            
              Eslami, Motahhare,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://openreview.net/pdf?id=DTYFRzRPQn" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion-based generative models have emerged as powerful tools for synthesizing anatomically realistic computed tomography (CT) scans from free-text prompts but remain opaque when delineating token influence on the conditioned CT volume. This lack of interpretability limits their clinical applicability, trustworthiness, and adoption across diagnostic and decision-support scenarios. We present a token-wise voxel attribution method for 3D text-to-image diffusion models that leverages cross-attention in U-Net‚Äìbased architectures to extract individual token attention maps for synthetic CT scans. Our method visualizes individual, joint, or aggregated token-level voxel attributions during CT synthesis, helping to alleviate concerns about model transparency. This lays the groundwork for practical methods and structured explanations illustrating what aspects of attribution work well, where current limitations lie, and how researchers might approach explainable AI for 3D text-to-image diffusion models in radiology moving forward.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">bradshaw2025towardinte</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Toward Interpretable 3D Diffusion in Radiology: Token-Wise Attribution for Text-to-CT Synthesis}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bradshaw, Aidan and Morrison, Katelyn and Mathur, Arpit and Dai, Weicheng and Eslami, Motahhare and Perer, Adam}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Medical Imaging with Deep Learning-Short Papers, 2025}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{Medical Imaging with Deep Learning-Short Papers}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://openreview.net/pdf?id=DTYFRzRPQn}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2025ahumancent" class="col-sm-8">
    
      <div class="title">A Human-Centered Approach to Identifying Promises, Risks, &amp; Challenges of Text-to-Image Generative AI in Radiology</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Mathur, Arpit,
            
          
        
          
          
          
          
          
          

          

          
            
              Bradshaw, Aidan,
            
          
        
          
          
          
          
          
          

          

          
            
              Wartmann, Tom,
            
          
        
          
          
          
          
          
          

          

          
            
              Lundi, Steven,
            
          
        
          
          
          
          
          
          

          

          
            
              Zandifar, Afrooz,
            
          
        
          
          
          
          
          
          

          

          
            
              Dai, Weichang,
            
          
        
          
          
          
          
          
          

          

          
            
              Batmanghelich, Kayhan,
            
          
        
          
          
          
          
          
          

          

          
            
              Eslami, Motahhare,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://ojs.aaai.org/index.php/AIES/article/download/36672/38810" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>As text-to-image generative models rapidly improve, AI researchers are making significant advances in developing domain-specific models capable of generating complex medical imagery from text prompts. Despite this, these technical advancements have overlooked whether and how medical professionals would benefit from and use text-to-image generative AI (GenAI) in practice. By developing domain-specific GenAI without involving stakeholders, we risk the potential of building models that are either not useful or even more harmful than helpful. In this paper, we adopt a human-centered approach to responsible model development by involving stakeholders in evaluating and reflecting on the promises, risks, and challenges of a novel text-to-CT Scan GenAI model. Through exploratory model prompting activities, we uncover the perspectives of medical students, radiology trainees, and radiologists on the role that text-to-CT Scan GenAI can play across medical education, training, and practice. This human-centered approach additionally enabled us to surface technical challenges and domain-specific risks of generating synthetic medical images. We conclude by reflecting on the implications of medical text-to-image GenAI.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2025ahumancent</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Human-Centered Approach to Identifying Promises, Risks, &amp; Challenges of Text-to-Image Generative AI in Radiology}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Mathur, Arpit and Bradshaw, Aidan and Wartmann, Tom and Lundi, Steven and Zandifar, Afrooz and Dai, Weichang and Batmanghelich, Kayhan and Eslami, Motahhare and Perer, Adam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1758-1770}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society 8 (2 ..., 2025}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://ojs.aaai.org/index.php/AIES/article/download/36672/38810}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Journal Paper</abbr>
    
  
  </div>

  <div id="spitzer2025imperfecti" class="col-sm-8">
    
      <div class="title">Imperfections of XAI: Phenomena Influencing AI-Assisted Decision-Making</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Spitzer, Philipp,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Turri, Violet,
            
          
        
          
          
          
          
          
          

          

          
            
              Feng, Michelle,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>,
            
          
        
          
          
          
          
          
          

          

          
            
              and K√ºhl, Niklas
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM Transactions on Interactive Intelligent Systems</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://dl.acm.org/doi/pdf/10.1145/3750052" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>With the increasing use of AI, recent research in human‚Äìcomputer interaction explores Explainable AI (XAI) to make AI advice more interpretable. While research addresses the effects of incorrect AI advice on AI-assisted decision-making, the impact of incorrect explanations is neglected so far. Additionally, recent work shows that not only different explanation modalities impact decision-makers, but also human factors play a critical role. To analyze relevant phenomena influencing AI-assisted decision-making, this work explores the impacting factors by conceptualizing theories of appropriate reliance and taking the first steps toward empirical evidence. We show that humans‚Äô reliance on AI and the human‚ÄìAI team performance are impacted by imperfect XAI in a study with 136 participants. Additionally, we find that cognitive styles affect decision-making in different explanation modalities. Hence, we shed light on ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">spitzer2025imperfecti</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Journal Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Imperfections of XAI: Phenomena Influencing AI-Assisted Decision-Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Spitzer, Philipp and Morrison, Katelyn and Turri, Violet and Feng, Michelle and Perer, Adam and K√ºhl, Niklas}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Transactions on Interactive Intelligent Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-40}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{ACM Transactions on Interactive Intelligent Systems 15 (3), 1-40, 2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/pdf/10.1145/3750052}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="morrison2025establishi" class="col-sm-8">
    
      <div class="title">Establishing the Cooperative Game Wavelength as a Testbed to Explore Mutual Theory of Mind</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Ashktorab, Zahra,
            
          
        
          
          
          
          
          
          

          

          
            
              Bouneffouf, Djallel,
            
          
        
          
          
          
          
          
          

          

          
            
              and Enrique, Gabriel
            
          
        
      </div>

      <div class="periodical">
      
        <em>ToM4AI 2025</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://bit.ly/4op0ui8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Machine learning (ML) and humancentered AI (HCAI) researchers have considered numerous methods to evaluate Theory of Mind (ToM)-like capabilities in artiƒÑcial intelligence (AI). These methods have independently captured multiple aspects of ToM capabilities (ie, beliefs, knowledge). Recent research has proposed exploring Mutual Theory of Mind (MToM) as a way to understand how a human≈†s mental model and an AI≈†s user model can be mutually shaped to beneƒÑt future interactions. However, there is a lack of methods for understanding the development and impact of MToM-like capabilities in human-AI teams. We propose using a collaborative party game called Wavelength as a testbed to explore the complexities of MToM-like capabilities in human-AI teams. We compare Wavelength to other methods (ie, Overcooked, Hanabi) and discuss how game mechanics help players mutually construct, recognize, and revise their models of their teammates. Lastly, we brieƒÜy suggest how future work can explore MToM with Wavelength.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2025establishi</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Establishing the Cooperative Game Wavelength as a Testbed to Explore Mutual Theory of Mind}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Ashktorab, Zahra and Bouneffouf, Djallel and Enrique, Gabriel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ToM4AI 2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{54}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{ToM4AI 2025, 54, 2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://bit.ly/4op0ui8}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop</abbr>
    
  
  </div>

  <div id="spitzer2025hybridauto" class="col-sm-8">
    
      <div class="title">Hybrid Automation Experiences‚ÄìCommunication, Coordination, and Collaboration within Human-AI Teams</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Spitzer, Philipp,
            
          
        
          
          
          
          
          
          

          

          
            
              Baldauf, Matthias,
            
          
        
          
          
          
          
          
          

          

          
            
              Palanque, Philippe,
            
          
        
          
          
          
          
          
          

          

          
            
              Roto, Virpi,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Zipperling, Domenique,
            
          
        
          
          
          
          
            
              
            
          
          
          

          

          
            
              and Holstein, Joshua
            
          
        
      </div>

      <div class="periodical">
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://dl.acm.org/doi/abs/10.1145/3706599.3706738" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Automated systems and AI-assisted workflows are evolving from support tools to sophisticated collaborators in so-called ‚Äúhybrid‚Äù teams with human and AI-based members. This evolution presents new challenges and opportunities in the field of ‚ÄúAutomation Experience‚Äù, particularly in how these team members communicate, coordinate, and collaborate. This workshop aims to contribute to the design of automated systems that augment humans‚Äô capabilities, maintain human autonomy, and create positive automation experiences in human-AI teams. Through presentations, a keynote talk, discussions, and interactive collaborative activities, researchers and practitioners from different fields will address challenges regarding communication, coordination, and collaboration within hybrid human-AI teams. The workshop aims to spark innovative research directions and foster collaborative interdisciplinary initiatives that ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">spitzer2025hybridauto</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hybrid Automation Experiences‚ÄìCommunication, Coordination, and Collaboration within Human-AI Teams}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Spitzer, Philipp and Baldauf, Matthias and Palanque, Philippe and Roto, Virpi and Morrison, Katelyn and Zipperling, Domenique and Holstein, Joshua}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-6}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Proceedings of the Extended Abstracts of the CHI Conference on Human Factors ..., 2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/abs/10.1145/3706599.3706738}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Journal Paper</abbr>
    
  
  </div>

  <div id="spitzer2024dontbefool" class="col-sm-8">
    
      <div class="title">Don‚Äôt be Fooled: The Misinformation Effect of Explanations in Human-AI Collaboration</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Spitzer, Philipp,
            
          
        
          
          
          
          
            
              
            
          
          
          

          

          
            
              Holstein, Joshua,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://www.thecoalalab.com/kenholstein" target="_blank" rel="noopener noreferrer">Holstein, Kenneth</a>,
            
          
        
          
          
          
          
          
          

          

          
            
              Satzger, Gerhard,
            
          
        
          
          
          
          
          
          

          

          
            
              and K√ºhl, Niklas
            
          
        
      </div>

      <div class="periodical">
      
        <em>International Journalof Human‚ÄìComputer Interaction</em>
      
      
        2025
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/pdf/2409.12809" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Across various applications, humans increasingly use black-box artificial intelligence (AI) systems without insight into these systems‚Äô reasoning. To counter this opacity, explainable AI (XAI) methods promise enhanced transparency and interpretability. While recent studies have explored how XAI affects human-AI collaboration, few have examined the potential pitfalls caused by incorrect explanations. The implications for humans can be far-reaching but have not been explored extensively. To investigate this, we ran a study (n=160) on AI-assisted decision-making in which humans were supported by XAI. Our findings reveal a misinformation effect when incorrect explanations accompany correct AI advice with implications post-collaboration. This effect causes humans to infer flawed reasoning strategies, hindering task execution and demonstrating impaired procedural knowledge. Additionally, incorrect explanations compromise human-AI team-performance during collaboration. With our work, we contribute to HCI by providing empirical evidence for the negative consequences of incorrect explanations on humans post-collaboration and outlining guidelines for designers of AI.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">spitzer2024dontbefool</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Journal Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Don't be Fooled: The Misinformation Effect of Explanations in Human-AI Collaboration}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Spitzer, Philipp and Holstein, Joshua and Morrison, Katelyn and Holstein, Kenneth and Satzger, Gerhard and K√ºhl, Niklas}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{International Journalof Human‚ÄìComputer Interaction}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2409.12809}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2024</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="xu2024medsyntext" class="col-sm-8">
    
      <div class="title">MedSyn: Text-guided Anatomy-aware Synthesis of High-Fidelity 3D CT Images</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Xu, Yanwu,
            
          
        
          
          
          
          
          
          

          

          
            
              Sun, Li,
            
          
        
          
          
          
          
          
          

          

          
            
              Peng, Wei,
            
          
        
          
          
          
          
          
          

          

          
            
              Jia, Shuyue,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>,
            
          
        
          
          
          
          
          
          

          

          
            
              Zandifar, Afrooz,
            
          
        
          
          
          
          
          
          

          

          
            
              Visweswaran, Shyam,
            
          
        
          
          
          
          
          
          

          

          
            
              Eslami, Motahhare,
            
          
        
          
          
          
          
          
          

          

          
            
              and Batmanghelich, Kayhan
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE Transactions on Medical Imaging</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://arxiv.org/pdf/2310.03559" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper introduces an innovative methodology for producing high-quality 3D lung CT images guided by textual information. While diffusion-based generative models are increasingly used in medical imaging, current state-of-the-art approaches are limited to low-resolution outputs and underutilize radiology reports‚Äô abundant information. The radiology reports can enhance the generation process by providing additional guidance and offering fine-grained control over the synthesis of images. Nevertheless, expanding text-guided generation to high-resolution 3D images poses significant memory and anatomical detail-preserving challenges. Addressing the memory issue, we introduce a hierarchical scheme that uses a modified UNet architecture. We start by synthesizing low-resolution images conditioned on the text, serving as a foundation for subsequent generators for complete volumetric data. To ensure the ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xu2024medsyntext</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MedSyn: Text-guided Anatomy-aware Synthesis of High-Fidelity 3D CT Images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Yanwu and Sun, Li and Peng, Wei and Jia, Shuyue and Morrison, Katelyn and Perer, Adam and Zandifar, Afrooz and Visweswaran, Shyam and Eslami, Motahhare and Batmanghelich, Kayhan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging, 2024}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2310.03559}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2024theimpacto" class="col-sm-8">
    
      <div class="title">The Impact of Imperfect XAI on Human-AI Decision-Making</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Spitzer, Philipp,
            
          
        
          
          
          
          
          
          

          

          
            
              Turri, Violet,
            
          
        
          
          
          
          
          
          

          

          
            
              Feng, Michelle,
            
          
        
          
          
          
          
          
          

          

          
            
              K√ºhl, Niklas,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW)</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/pdf/2307.13566.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings. Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools. Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers‚Äô collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice. Few studies acknowledge the possibility of the explanations being incorrect even if the AI advice is correct. Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making. In this work, we contribute a robust, mixed-methods user study with 136 ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2024theimpacto</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Impact of Imperfect XAI on Human-AI Decision-Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Spitzer, Philipp and Turri, Violet and Feng, Michelle and K√ºhl, Niklas and Perer, Adam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social ..., 2024}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/pdf/2307.13566.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="turri2024transparen" class="col-sm-8">
    
      <div class="title">Transparency in the wild: Navigating transparency in a deployed ai system to broaden need-finding approaches</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Turri, Violet,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Robinson, Katherine-Marie,
            
          
        
          
          
          
          
          
          

          

          
            
              Abidi, Collin,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>,
            
          
        
          
          
          
          
          
          

          

          
            
              Forlizzi, Jodi,
            
          
        
          
          
          
          
          
          

          

          
            
              and Dzombak, Rachel
            
          
        
      </div>

      <div class="periodical">
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="https://dl.acm.org/doi/pdf/10.1145/3630106.3658985" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Transparency is a critical component when building artificial intelligence (AI) decision-support tools, especially for contexts in which AI outputs impact people or policy. Effectively identifying and addressing user transparency needs in practice remains a challenge. While a number of guidelines and processes for identifying transparency needs have emerged, existing methods tend to approach need-finding with a limited focus that centers around a narrow set of stakeholders and transparency techniques. To broaden this perspective, we employ numerous need-finding methods to investigate transparency mechanisms in a widely deployed AI-decision support tool developed by a wildlife conservation non-profit. Throughout our 5-month case study, we conducted need-finding through semi-structured interviews with end-users, analysis of the tool‚Äôs community forum, experiments with their ML model, and analysis of ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">turri2024transparen</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Transparency in the wild: Navigating transparency in a deployed ai system to broaden need-finding approaches}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Turri, Violet and Morrison, Katelyn and Robinson, Katherine-Marie and Abidi, Collin and Perer, Adam and Forlizzi, Jodi and Dzombak, Rachel}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1494-1514}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 ACM Conference on Fairness, Accountability, and ..., 2024}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/pdf/10.1145/3630106.3658985}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2024aipoweredr" class="col-sm-8">
    
      <div class="title">AI-Powered Reminders for Collaborative Tasks: Experiences and Futures</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://www.microsoft.com/en-us/research/people/shamsi/" target="_blank" rel="noopener noreferrer">Iqbal, Shamsi T</a>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://erichorvitz.com" target="_blank" rel="noopener noreferrer">Horvitz, Eric</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proceedings of the ACM on Human-Computer Interaction</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Email continues to serve as a central medium for managing collaborations. While unstructured email messaging is lightweight and conducive to coordination, it is easy to overlook commitments and requests for collaborations that are embedded in the text of free-flowing communications. Twenty-one years ago, Bellotti et al. proposed TaskMaster with the goal of redesigning the email interface to have explicit task management capabilities. Recently, AI-based task recognition and reminder services have been introduced in major email systems as one approach to managing asynchronous collaborations. While these services have been provided to millions of people around the world, there is little understanding of how people interact with and benefit from them. We explore knowledge workers‚Äô experiences with Microsoft‚Äôs Viva Daily Briefing Email to better understand how AI-powered reminders can support ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2024aipoweredr</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AI-Powered Reminders for Collaborative Tasks: Experiences and Futures}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Iqbal, Shamsi T and Horvitz, Eric}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the ACM on Human-Computer Interaction}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{CSCW1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-20}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Proceedings of the ACM on Human-Computer Interaction 8 (CSCW1), 1-20, 2024}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="morrison2024trew" class="col-sm-8">
    
      <div class="title">Imperfect Natural Language Explanations in Human-AI Decision-Making</div>
      <div class="author">
        
          
          
          
          
            
              
            
          
          
          

          

          
            
              Morrison, K.,
            
          
        
          
          
          
          
          
          

          

          
            
              Spitzer, P.,
            
          
        
          
          
          
          
          
          

          

          
            
              Turri, V.,
            
          
        
          
          
          
          
          
          

          

          
            
              Feng, M.,
            
          
        
          
          
          
          
          
          

          

          
            
              K√ºhl, N.,
            
          
        
          
          
          
          
            
              
            
          
          
          

          

          
            
              and Perer, A.
            
          
        
      </div>

      <div class="periodical">
      
        <em>TREW Workshop at ACM CHI 2024</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/24_Chi_Trew_ImperfectXAI.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2024trew</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Imperfect Natural Language Explanations in Human-AI Decision-Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, K. and Spitzer, P. and Turri, V. and Feng, M. and K√ºhl, N. and Perer, A.}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{TREW Workshop at ACM CHI 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{24_Chi_Trew_ImperfectXAI.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2023evaluating" class="col-sm-8">
    
      <div class="title">Evaluating the Impact of Human Explanation Strategies on Human-AI Visual Decision-Making</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://donghoon.io/" target="_blank" rel="noopener noreferrer">Shin, Donghoon</a>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://www.thecoalalab.com/kenholstein" target="_blank" rel="noopener noreferrer">Holstein, Kenneth</a>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/23_cscw_explanation_characteristics.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Artificial intelligence (AI) is increasingly being deployed in high-stakes domains, such as disaster relief and radiology, to aid practitioners during the decision-making process. Explainable AI techniques have been developed and deployed to provide users insights into why the AI made certain predictions. However, recent research suggests that these techniques may confuse or mislead users. We conducted a series of two studies to uncover strategies that humans use to explain decisions and then understand how those explanation strategies impact visual decision-making. In our first study, we elicit explanations from humans when assessing and localizing damaged buildings after natural disasters from satellite imagery and identify four core explanation strategies that humans employed. We then follow up by studying the impact of these explanation strategies by framing the explanations from Study 1 as if they were ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">morrison2023evaluating</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evaluating the Impact of Human Explanation Strategies on Human-AI Visual Decision-Making}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Shin, Donghoon and Holstein, Kenneth and Perer, Adam}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social ..., 2023}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW)}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{23_cscw_explanation_characteristics.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2023eyeintoaie" class="col-sm-8">
    
      <div class="title">Eye into AI: Evaluating the Interpretability of Explainable AI Techniques through a Game With a Purpose</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Jain, Mayank,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="http://replayable.net" target="_blank" rel="noopener noreferrer">Hammer, Jessica</a>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW)</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recent developments in explainable AI (XAI) aim to improve the transparency of black-box models. However, empirically evaluating the interpretability of these XAI techniques is still an open challenge. The most common evaluation method is algorithmic performance, but such an approach may not accurately represent how interpretable these techniques are to people. A less common but growing evaluation strategy is to leverage crowd-workers to provide feedback on multiple XAI techniques to compare them. However, these tasks often feel like work and may limit participation. We propose a novel, playful, human-centered method for evaluating XAI techniques: a Game With a Purpose (GWAP), Eye into AI, that allows researchers to collect human evaluations of XAI at scale. We provide an empirical study demonstrating how our GWAP supports evaluating and comparing the agreement between three popular XAI ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2023eyeintoaie</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Eye into AI: Evaluating the Interpretability of Explainable AI Techniques through a Game With a Purpose}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Jain, Mayank and Hammer, Jessica and Perer, Adam}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social Computing (CSCW)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{ACM SIGCHI Conference on Computer-Supported Cooperative Work &amp; Social ..., 2023}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2023sharedinte" class="col-sm-8">
    
      <div class="title">Shared interest... sometimes: Understanding the alignment between human perception, vision architectures, and saliency map techniques</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Mehra, Ankita,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://perer.org/" target="_blank" rel="noopener noreferrer">Perer, Adam</a>
            
          
        
      </div>

      <div class="periodical">
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
    
      
      <a href="/assets/pdf/23_XAI4CV_cvpr.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Empirical studies have shown that attention-based architectures outperform traditional convolutional neural networks (CNN) in terms of accuracy and robustness. As a result, attention-based architectures are increasingly used in high-stakes domains such as radiology and wildlife conservation to aid in decision-making. However, understanding how attention-based architectures compare to CNNs regarding alignment with human perception is still under-explored. Previous studies exploring how vision architectures align with human perception evaluate a single architecture with multiple explainability techniques or multiple architectures with a single explainability technique. Through an empirical analysis, we investigate how two attention-based architectures and two CNNs for two saliency map techniques align with the ground truth for human perception on 100 images from an interpretability benchmark dataset. Using the Shared Interest metrics, we found that CNNs align more with human perception when using the XRAI saliency map technique. However, we found the opposite for Grad-CAM. We discuss the implications of our analysis for human-centered explainable AI and introduce directions for future work.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">morrison2023sharedinte</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Shared interest... sometimes: Understanding the alignment between human perception, vision architectures, and saliency map techniques}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Mehra, Ankita and Perer, Adam}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3776-3781}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern ..., 2023}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{23_XAI4CV_cvpr.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="aswal2022towardsgen" class="col-sm-8">
    
      <div class="title">Towards Generating Human-Centered Saliency Maps without Significantly Sacrificing Accuracy</div>
      <div class="author">
        
          
          
          
          
          
          

          

          
            
              Aswal, Vivek,
            
          
        
          
          
          
          
          
          

          

          
            
              Kao, Gore,
            
          
        
          
          
          
          
          
          

          

          
            
              Kim, Seo Young,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <span class="author-self">Morrison, Katelyn</span>
            
          
        
      </div>

      <div class="periodical">
      
        <em>NeuroVision 2022 Workshop at CVPR</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="http://katelyn98.github.io/blog/2022/vlr-project/" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
      
      <a href="/assets/pdf/19_CameraReady_CVPR2022_NeuroVision_SHORT_CameraReady.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
      
      <a href="/assets/pdf/CVPR_Lightning_Talk.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a>
      
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>As deep neural networks make significant advances in computer vision tasks, they are being deployed in several high-stakes domains. However, these models are not always semantically meaningful to humans as traditional interpretability techniques are quantitatively driven. Therefore, we explore how to generate saliency maps that are more similar to human attention without significantly sacrificing the model performance. We conduct an empirical study to understand how current object detection models compare to human centered saliency maps. Additionally, we present different data augmentation techniques such as Selective Erasing and Selective Inpainting along with the prevelant non-trivial transforms to evaluate the impact of human-centered data augmentation. With less than 3% mAP difference, we observe that data augmentations that are derived from predicted human attention improves the MAE and IoU between the model saliency and predicted attention. Visualization and more details are at here.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">aswal2022towardsgen</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards Generating Human-Centered Saliency Maps without Significantly Sacrificing Accuracy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Aswal, Vivek and Kao, Gore and Kim, Seo Young and Morrison, Katelyn}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{NeuroVision 2022 Workshop at CVPR}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{NeuroVision 2022 Workshop at CVPR, 2022}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{http://katelyn98.github.io/blog/2022/vlr-project/}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{19_CameraReady_CVPR2022_NeuroVision_SHORT_CameraReady.pdf}</span><span class="p">,</span>
  <span class="na">slides</span> <span class="p">=</span> <span class="s">{CVPR_Lightning_Talk.pdf}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="morrison2021exploringc" class="col-sm-8">
    
      <div class="title">Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
          
          

          

          
            
              Gilby, Benjamin,
            
          
        
          
          
          
          
          
          

          

          
            
              Lipchak, Colton,
            
          
        
          
          
          
          
          
          

          

          
            
              Mattioli, Adam,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://people.cs.pitt.edu/~kovashka/" target="_blank" rel="noopener noreferrer">Kovashka, Adriana</a>
            
          
        
      </div>

      <div class="periodical">
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/abs/2106.13122" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
      
      <a href="/assets/pdf/exploring_corruption.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
      <a href="https://github.com/katelyn98/CorruptionRobustness" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Recently, vision transformers and MLP-based models have been developed in order to address some of the prevalent weaknesses in convolutional neural networks. Due to the novelty of transformers being used in this domain along with the self-attention mechanism, it remains unclear to what degree these architectures are robust to corruptions. Despite some works proposing that data augmentation remains essential for a model to be robust against corruptions, we propose to explore the impact that the architecture has on corruption robustness. We find that vision transformer architectures are inherently more robust to corruptions than the ResNet-50 and MLP-Mixers. We also find that vision transformers with 5 times fewer parameters than a ResNet-50 have more shape bias. Our code is available to reproduce.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">morrison2021exploringc</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Gilby, Benjamin and Lipchak, Colton and Mattioli, Adam and Kovashka, Adriana}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Uncertainty and Robustness in Deep Learning Workshop at ICML 2021, 2021}</span><span class="p">,</span>
  <span class="na">conference</span> <span class="p">=</span> <span class="s">{Uncertainty and Robustness in Deep Learning Workshop at ICML 2021}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2106.13122}</span><span class="p">,</span>
  <span class="na">pdf</span> <span class="p">=</span> <span class="s">{exploring_corruption.pdf}</span><span class="p">,</span>
  <span class="na">code</span> <span class="p">=</span> <span class="s">{https://github.com/katelyn98/CorruptionRobustness}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Conference Paper</abbr>
    
  
  </div>

  <div id="morrison2020usingobjec" class="col-sm-8">
    
      <div class="title">Using Object Tracking Techniques to Non-Invasively Measure Thoracic Rotation Range of Motion</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <span class="author-self">Morrison, Katelyn</span>,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              <a href="https://www.danyatesdesign.com/" target="_blank" rel="noopener noreferrer">Yates, Daniel</a>,
            
          
        
          
          
          
          
          
          

          

          
            
              Roman, Maya,
            
          
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            
              and <a href="https://www.engineering.pitt.edu/people/faculty/william-buddy-clark/" target="_blank" rel="noopener noreferrer">Clark, William W</a>
            
          
        
      </div>

      <div class="periodical">
      
        <em>Adjunct Proceedings of the ACM International Conference on Multimodal Interaction (ICMI 2020), Utrecht, the Netherlands</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="" class="btn btn-sm z-depth-0" role="button">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Different measuring instruments, such as a goniometer, have been used by clinicians to measure a patient‚Äôs ability to rotate their thoracic spine. Despite the simplicity of goniometers, this instrument requires the user to decipher the resulting measurement properly. The correctness of these measurements are imperative for clinicians to properly identify and evaluate injuries or help athletes enhance their overall performance. This paper introduces a goniometer-free, noninvasive measuring technique using a Raspberry Pi, a Pi Camera module, and software for clinicians to measure a subject‚Äôs thoracic rotation range of motion (ROM) when administering the seated rotation technique with immediate measurement feedback. Determining this measurement is achieved by applying computer vision object tracking techniques on a live video feed from the Pi Camera that is secured on the ceiling above the subject ...</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2020usingobjec</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Conference Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Using Object Tracking Techniques to Non-Invasively Measure Thoracic Rotation Range of Motion}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn and Yates, Daniel and Roman, Maya and Clark, William W}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Adjunct Proceedings of the ACM International Conference on Multimodal Interaction (ICMI 2020), Utrecht, the Netherlands}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{Adjunct Proceedings of the ACM International Conference on Multimodal ..., 2020}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">Workshop Paper</abbr>
    
  
  </div>

  <div id="morrison2020reducingdi" class="col-sm-8">
    
      <div class="title">Reducing Discrimination in Learning Algorithms for Social Good in Sociotechnical Systems</div>
      <div class="author">
        
          
          
          
          
            
              
                
                
          
          
          

          

          
            <span class="author-self">Morrison, Katelyn</span>
          
        
      </div>

      <div class="periodical">
      
        <em>AI for Social Good Workshop at IJCAI-PRICAI 2020</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://arxiv.org/abs/2011.13988" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Sociotechnical systems within cities are now equipped with machine learning algorithms in hopes to increase efficiency and functionality by modeling and predicting trends. Machine learning algorithms have been applied in these domains to address challenges such as balancing the distribution of bikes throughout a city and identifying demand hotspots for ride sharing drivers. However, these algorithms applied to challenges in sociotechnical systems have exacerbated social inequalities due to previous bias in data sets or the lack of data from marginalized communities. In this paper, I will address how smart mobility initiatives in cities use machine learning algorithms to address challenges. I will also address how these algorithms unintentionally discriminate against features such as socioeconomic status to motivate the importance of algorithmic fairness. Using the bike sharing program in Pittsburgh, PA, I will present a position on how discrimination can be eliminated from the pipeline using Bayesian Optimization.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morrison2020reducingdi</span><span class="p">,</span>
  <span class="na">abbr</span> <span class="p">=</span> <span class="s">{Workshop Paper}</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reducing Discrimination in Learning Algorithms for Social Good in Sociotechnical Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morrison, Katelyn}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{AI for Social Good Workshop at IJCAI-PRICAI 2020}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">pub_year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">citation</span> <span class="p">=</span> <span class="s">{AI for Social Good Workshop at IJCAI-PRICAI 2020, 2020}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2011.13988}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
</ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    ¬© Copyright 2025 Katelyn C. Morrison.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
    Last updated: November 13, 2025.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  
<!-- Enable Tooltips -->
<script type="text/javascript">
$(function () {$('[data-toggle="tooltip"]').tooltip()})
</script>



<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>

---
layout: page
title: Insightful Saliency Maps
description: Final project for Data Visualization class in collaboration with Swetha Kannan.
img: /assets/img/DataVizFinalProject.gif
importance: 1
category: Interactive Visualizations
---

## Project Description

Explainability techniques for image classification such as saliency maps provide insight into which regions of the image influenced the prediction. Saliency techniques can assist data scientists in model debugging by identifying features in images that are not relevant to the image class. However, the static presentation of saliency maps withhold data scientists from further exploring model behavior on out-of-distribution data. Incorporating saliency maps in an interactive tool will enable data scientists to debug their models while understanding how their model behaves on out-of-distribution data. We present a protoype that incorporates saliency maps in an interactive, exploratory tool to showcase novel interactions that data scientists can experience with saliency maps. 

### Shape Bias

To learn more about shape bias, you can read this paper from ICLR 2019: [ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness](https://openreview.net/forum?id=Bygh9j09KX). 


## Working Demo 

Not all features are fully implemented yet (*still under construction - project due November 30th*).

[Demo](https://cmu-vis-2021.github.io/Human-vs-Machine-Final-Project/)

[Codebase](https://github.com/CMU-Vis-2021/Human-vs-Machine-Final-Project)
